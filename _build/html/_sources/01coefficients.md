---
myst:
  enable_extensions: ["colon_fence","amsmath"]
  dmath_allow_labels: True
---

# How the coefficients are calculated

Following {cite}`oladyshkin2012data` it can be noted that the way the conditions are set for the constructions of the polynomials leads to a way of determining them all in one time as the solution of a linear system of equations. 

The conditions to uniquely determine a polynomial are:
* The leading term must be 1.
* Every polynomial of degree $n$ must be orthogonal to all those of degree $n-1$.

Calling a polynomial of this king of degree $n$ as $\pi_n(x)$ (where $x\in \mathcal{X}$ is a random variable with probability distribution $w$), it follows immediately that $\pi_0(x) = 1$.\
The condition of orthogonality is defined as:

$$ \langle \pi_i,\pi_j\rangle_w = \int_{\mathcal{X}} \pi_i(x)\pi_j(x)w(x)dx = 0\quad\mbox{for }i\neq j $$ (eqn:orthogonality)

For the first polynomial ($\pi_1(x) = c_1^1x + c_1^0$) this results in:

$$
\begin{gather}
	\langle \pi_1,\pi_0\rangle_w = \int_{\mathcal{X}} \pi_1(x)\cdot1\cdot w(x)dx = 0\\
	c_1^1 = 1
\end{gather}
$$

which results in:

$$
\begin{gather}
	\int_{\mathcal{X}} \pi_1(x)\cdot1\cdot w(x)dx = 0 = c_1^1\mu_1 + c_1^0\mu_0 \\
	c_1^1 = 1
\end{gather}
$$

where, from now on, $\mu_i$ is the statistical moment of order $i$ ($\mu_i = \int_{\mathcal{X}}x^iw(x)dx$), so that $\mu_o = 1$. As said in the previous notebook, when $\mu_1 = 0$, we obtain $\pi_1(x) = x$.

The second polynomial, *i.e.* $\pi_2(x) = c_2^2x^2 + c_2^1x + c_2^0$, will then follow:

$$
\begin{gather}
	\int_{\mathcal{X}} \pi_2(x)\cdot1\cdot w(x)dx = 0 \\
	\int_{\mathcal{X}} \pi_2(x)\pi_1(x)w(x)dx = 0\\
	c_2^2 = 1
\end{gather}
$$

The known form for $\pi_1$ we arrive at the following system:

$$
\begin{gather}
	\mu_0c_2^0 + \mu_1c_2^1 + \mu_2c_2^2 = 0
	\mu_1c_2^0 + \mu_2c_2^1 + \mu_3c_2^2 = 0
	c_2^2 = 1
\end{gather}
$$

Or, in matrix form:

$$
\begin{bmatrix} 
	\mu_0&\mu_1&\mu_2\\
	\mu_1 & \mu_2 & \mu_3\\
	0 & 0 & 1
\end{bmatrix}\begin{bmatrix} c_2^0\\c_2^1\\c_2^2\end{bmatrix} = \begin{bmatrix} 0\\0\\1\end{bmatrix}
$$

Since the moments of the distribution can be easily calculated from the data generated by the distribution, the only thing left to compute all the coefficients is to invert the matrix. This same methodology can be applied tp polynomials of any degree, yielding for the polynomial $\pi_n = \sum_{i=0}^n c_n^ix^i$:

$$
\begin{bmatrix}
\mu_0 & \mu_1 & \dots & \mu_n\\
\mu_1 & \mu_2 & \dots & \mu_{n+1}\\
\vdots & \vdots & \ddots & \vdots\\
\mu_{n-1} & \mu_n & \dots & \mu_{2n-1}\\
0 & 0 & \dots & 1
\end{bmatrix}\begin{bmatrix} c_n^0\\c_n^1\\\vdots\\c_n^{n-1}\\c_n^n\end{bmatrix} = \begin{bmatrix} 0\\0\\\vdots\\1\end{bmatrix}
$$(eqn:moments-matrix)

This shows that, contrary to what had been done in the previous code, the is no need to integrate any function numerically and that only the knowledge of the first $2n-1$ moments of the distribution of the data is necessary in order to calculate all the coefficients of the expansion up to degree $n$.